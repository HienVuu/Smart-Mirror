import sys
import cv2
import mediapipe as mp
import speech_recognition as sr
import threading
import requests
import feedparser
import google.generativeai as genai
from PyQt5.QtWidgets import QApplication
from PyQt5.QtQml import QQmlApplicationEngine
from PyQt5.QtCore import QObject, pyqtSignal, QTimer, Qt, QTime, QDate
from PyQt5.QtGui import QImage
from PyQt5.QtQuick import QQuickImageProvider
import math
import os
import time
import subprocess 

# ---------------------------------------------------
# CONFIG
# ---------------------------------------------------

WEATHER_API_KEY = "abc" 
CITY = "Hanoi"
PHOTO_SAVE_PATH = r"photos" 
GEMINI_API_KEY = "abc" 

# FILE TH·ª∞C THI (SYSTEMC / C++ MOCK)
# T·ª± ƒë·ªông ph√°t hi·ªán h·ªá ƒëi·ªÅu h√†nh ƒë·ªÉ ch·ªçn t√™n file ƒë√∫ng
if os.name == 'nt': # Windows
    SYSTEMC_TIMER_EXEC = "camera_timer.exe"
    SYSTEMC_GESTURE_EXEC = "hand_decision.exe"
else: # Linux / Raspberry Pi
    SYSTEMC_TIMER_EXEC = "./camera_timer"
    SYSTEMC_GESTURE_EXEC = "./hand_decision"

# ---------------------------------------------------
# INIT GEMINI
# ---------------------------------------------------
ai_model = None
model_name_used = "Unknown"

try:
    genai.configure(api_key=GEMINI_API_KEY)
    print(">>> ƒêang kh·ªüi t·∫°o AI...")
    all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    
    priority_list = ["models/gemini-flash-latest", "models/gemini-1.5-flash", "models/gemini-pro"]
    selected_model = None
    
    for p in priority_list:
        if p in all_models:
            selected_model = p
            break
            
    if not selected_model and all_models:
        selected_model = all_models[0]

    if selected_model:
        ai_model = genai.GenerativeModel(selected_model)
        model_name_used = selected_model
        print(f">>> MODEL ƒê√É CH·ªåN: {selected_model}")
    else:
        print(">>> KH√îNG T√åM TH·∫§Y MODEL N√ÄO!")

except Exception as e:
    print(">>> L·ªñI INIT AI:", e)

# ---------------------------------------------------
# IMAGE PROVIDER
# ---------------------------------------------------
class LiveImageProvider(QQuickImageProvider):
    def __init__(self):
        super().__init__(QQuickImageProvider.Image)
        self.current_image = None

    def requestImage(self, id, size, requestedSize=None):
        if self.current_image is not None:
            return self.current_image, self.current_image.size()
        img = QImage(320, 240, QImage.Format_RGB888)
        img.fill(Qt.black)
        return img, img.size()

    def update_image(self, img):
        self.current_image = img

# ---------------------------------------------------
# VOICE WORKER
# ---------------------------------------------------
class VoiceWorker(threading.Thread):
    def __init__(self, callback):
        super().__init__()
        self.callback = callback
        self.recognizer = sr.Recognizer()
        self.daemon = True
        self.mics = sr.Microphone.list_microphone_names()
        self.device_index = 0
        
        for i, m in enumerate(self.mics):
            if "USB" in m or "Usb" in m:
                self.device_index = i
                break
        print(f"Voice Thread started on MIC index: {self.device_index}")

    def run(self):
        while True:
            try:
                with sr.Microphone(device_index=self.device_index) as source:
                    self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                    audio = self.recognizer.listen(source, timeout=None, phrase_time_limit=5)
                    try:
                        text = self.recognizer.recognize_google(audio, language="vi-VN")
                        print("User said:", text)
                        self.callback(text.lower())
                    except sr.UnknownValueError:
                        pass
                    except Exception as e:
                        print("Speech error:", e)
            except Exception as e:
                print("Voice thread fatal error:", e)

# ---------------------------------------------------
# BACKEND
# ---------------------------------------------------
class Backend(QObject):
    imageUpdated = pyqtSignal(str)
    updateClock = pyqtSignal(str, str)
    updateWeather = pyqtSignal(str, str)
    updateNews = pyqtSignal(str)
    updateAI = pyqtSignal(str)
    changePage = pyqtSignal(int)
    updateVoiceStatus = pyqtSignal(str)

    def __init__(self, img_provider):
        super().__init__()
        self.img_provider = img_provider
        self.cap = cv2.VideoCapture(0)

        self.mpHands = mp.solutions.hands
        self.hands = self.mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)
        self.mpDraw = mp.solutions.drawing_utils

        # Gesture state
        self.last_open_time = 0
        self.last_fist_time = 0
        
        # Context Data
        self.context_weather = "ƒêang c·∫≠p nh·∫≠t..."
        self.context_news = "ƒêang c·∫≠p nh·∫≠t..."

        # Timers
        self.timer = QTimer()
        self.timer.timeout.connect(self.game_loop)
        self.timer.start(30)

        self.weather_timer = QTimer()
        self.weather_timer.timeout.connect(self.fetch_weather)
        self.weather_timer.start(1800000)

        self.news_timer = QTimer()
        self.news_timer.timeout.connect(self.fetch_news)
        self.news_timer.start(600000)

        QTimer.singleShot(1000, self.fetch_weather)
        QTimer.singleShot(2000, self.fetch_news)

        self.voice_thread = VoiceWorker(self.process_voice)
        self.voice_thread.start()

    # --- WEATHER ---
    def fetch_weather(self):
        try:
            url = f"http://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={WEATHER_API_KEY}&units=metric&lang=vi"
            data = requests.get(url, timeout=5).json()
            if data.get("cod") != 200: return

            lat, lon = data['coord']['lat'], data['coord']['lon']
            temp = int(data['main']['temp'])
            desc = data["weather"][0]["description"]
            icon = data["weather"][0]["icon"]

            try:
                url_air = f"http://api.openweathermap.org/data/2.5/air_pollution?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}"
                aqi = requests.get(url_air, timeout=5).json()['list'][0]['main']['aqi']
            except:
                aqi = "?"

            self.context_weather = f"T·∫°i {CITY}: {temp}¬∞C, {desc}. AQI {aqi}."
            self.updateWeather.emit(f"{temp}¬∞C", desc.title() + "|" + icon)
        except Exception as e:
            print("Fetch Weather Error:", e)

    def get_fresh_weather_info(self):
        # H√†m r√∫t g·ªçn ƒë·ªÉ l·∫•y weather khi h·ªèi AI
        try:
            url = f"http://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={WEATHER_API_KEY}&units=metric&lang=vi"
            data = requests.get(url, timeout=5).json()
            temp = int(data['main']['temp'])
            desc = data["weather"][0]["description"]
            return f"{temp}¬∞C, {desc}"
        except:
            return "Kh√¥ng r√µ"

    # --- NEWS ---
    def fetch_news(self):
        try:
            rss_urls = ["https://vnexpress.net/rss/tin-moi-nhat.rss"]
            display_titles = [e.title for e in feedparser.parse(rss_urls[0]).entries[:10]]
            self.context_news = "Tin t·ª©c: " + "; ".join(display_titles[:5])
            self.updateNews.emit("TIN M·ªöI: " + "   ‚ú¶   ".join(display_titles))
        except Exception as e:
            print("News Error:", e)

    # --- VOICE & SYSTEMC PHOTO ---
    def process_voice(self, text):
        corrections = {
            "ti√™u c·ª±c t√≠m": "tia c·ª±c t√≠m",
            "ch·ª•p h√¨nh": "ch·ª•p ·∫£nh",
            "l∆∞u ·∫£nh": "ch·ª•p ·∫£nh"
        }
        for wrong, right in corrections.items():
            if wrong in text: text = text.replace(wrong, right)

        self.updateVoiceStatus.emit("üó£ " + text)

        if "ch·ª•p ·∫£nh" in text:
            self.take_photo_with_systemc()
            return

        if ai_model:
            self.ask_gemini(text)
        else:
            self.updateAI.emit("L·ªói: Kh√¥ng t√¨m th·∫•y AI.")

    def take_photo_with_systemc(self):
        # Ch·ª©c nƒÉng ch·ª•p ·∫£nh c√≥ s·ª≠ d·ª•ng SystemC Timer (n·∫øu c√≥ file)
        try:
            if not os.path.exists(PHOTO_SAVE_PATH):
                os.makedirs(PHOTO_SAVE_PATH)
            
            self.changePage.emit(1)
            self.updateAI.emit("K√≠ch ho·∫°t Timer ph·∫ßn c·ª©ng...")
            
            # Ki·ªÉm tra file th·ª±c thi timer
            if os.path.exists(SYSTEMC_TIMER_EXEC):
                process = subprocess.Popen(
                    [SYSTEMC_TIMER_EXEC], 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE,
                    text=True
                )
                while True:
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        clean_out = output.strip()
                        if "T-minus" in clean_out:
                            self.updateAI.emit(f"ƒê·∫øm ng∆∞·ª£c: {clean_out.split(' ')[-1]}")
            else:
                # Fallback n·∫øu ch∆∞a build file C++ timer
                print("Kh√¥ng t√¨m th·∫•y file timer C++, ch·∫°y fallback Python.")
                for i in range(3, 0, -1):
                    self.updateAI.emit(str(i))
                    time.sleep(1)

            ret, frame = self.cap.read()
            if ret:
                frame = cv2.flip(frame, 1)
                timestamp = int(time.time())
                filename = f"{PHOTO_SAVE_PATH}/anh_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                self.updateAI.emit("ƒê√£ ch·ª•p xong!")
        except Exception as e:
            print("Photo Error:", e)
            self.updateAI.emit("L·ªói ch·ª•p ·∫£nh.")

    def ask_gemini(self, text):
        self.updateAI.emit("ƒêang suy nghƒ©...")
        self.changePage.emit(1)
        
        def run_ai():
            try:
                info = self.get_fresh_weather_info() if "th·ªùi ti·∫øt" in text else self.context_weather
                sys_prompt = f"Tr·∫£ l·ªùi ng·∫Øn g·ªçn d∆∞·ªõi 3 c√¢u. Th·ªùi gian: {QTime.currentTime().toString()}. D·ªØ li·ªáu: {info}. C√¢u h·ªèi: {text}"
                res = ai_model.generate_content(sys_prompt)
                if res and res.text:
                    self.updateAI.emit(res.text.strip())
            except Exception as e:
                self.updateAI.emit(f"L·ªói AI: {str(e)[:40]}...")

        threading.Thread(target=run_ai).start()

    # ---------------------------------------------------
    # GESTURE WITH SYSTEMC / C++ MOCK INTEGRATION
    # ---------------------------------------------------
    
    def run_systemc_decision(self, finger_count):
        """
        G·ªçi file th·ª±c thi C++ (hand_decision.exe) ƒë·ªÉ ra quy·∫øt ƒë·ªãnh
        Input: S·ªë l∆∞·ª£ng ng√≥n tay (int)
        Output: 1 (Open), 0 (Close), -1 (Hold)
        """
        try:
            if not os.path.exists(SYSTEMC_GESTURE_EXEC):
                print(f"L·ªñI: Kh√¥ng t√¨m th·∫•y file {SYSTEMC_GESTURE_EXEC}")
                return -1 # Kh√¥ng l√†m g√¨ n·∫øu thi·∫øu file

            # G·ªçi process
            cmd = [SYSTEMC_GESTURE_EXEC, str(finger_count)]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # ƒê·ªçc k·∫øt qu·∫£ in ra t·ª´ C++ (stdout)
            output = result.stdout.strip()
            if output:
                return int(output)
            return -1
        except Exception as e:
            print(f"SystemC Call Error: {e}")
            return -1

    def detect_gesture(self, handLms):
        lm = handLms.landmark
        tips = [4, 8, 12, 16, 20]
        pips = [3, 6, 10, 14, 18]

        finger_open = []
        # Logic ƒë∆°n gi·∫£n ƒë·ªÉ ƒë·∫øm ng√≥n tay
        # L∆∞u √Ω: Ng√≥n c√°i check x ho·∫∑c y t√πy h∆∞·ªõng tay, ·ªü ƒë√¢y d√πng t·∫°m logic y cho ƒë∆°n gi·∫£n
        for tip, pip in zip(tips[1:], pips[1:]):
            finger_open.append(lm[tip].y < lm[pip].y)

        # X·ª≠ l√Ω ri√™ng ng√≥n c√°i (t∆∞∆°ng ƒë·ªëi)
        if lm[tips[0]].x < lm[pips[0]].x: 
            finger_open.append(True)
        
        total_open = sum(finger_open)

        # --- G·ªåI HARDWARE SIMULATION ---
        decision = self.run_systemc_decision(total_open)
        
        now = QTime.currentTime().msecsSinceStartOfDay()

        if decision == 1: # C++ b·∫£o M·ªû AI
            if self.last_open_time == 0:
                self.last_open_time = now
            elif now - self.last_open_time > 800:
                print(f">>> HARDWARE DECISION: OPEN ({total_open} fingers)")
                self.changePage.emit(1)
                self.last_open_time = 0
            self.last_fist_time = 0

        elif decision == 0: # C++ b·∫£o ƒê√ìNG AI
            if self.last_fist_time == 0:
                self.last_fist_time = now
            elif now - self.last_fist_time > 800:
                print(f">>> HARDWARE DECISION: CLOSE ({total_open} fingers)")
                self.changePage.emit(0)
                self.last_fist_time = 0
            self.last_open_time = 0
            
        else: # C++ b·∫£o Gi·ªØ nguy√™n (-1)
            self.last_open_time = 0
            self.last_fist_time = 0

    def game_loop(self):
        t = QTime.currentTime().toString("hh:mm")
        d = QDate.currentDate()
        self.updateClock.emit(t, f"Ng√†y {d.day()}/{d.month()}/{d.year()}")

        ret, frame = self.cap.read()
        if not ret: return

        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = self.hands.process(rgb)

        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                self.mpDraw.draw_landmarks(frame, handLms, self.mpHands.HAND_CONNECTIONS)
                self.detect_gesture(handLms)
        else:
            self.last_open_time = 0
            self.last_fist_time = 0

        h, w, ch = rgb.shape
        qt = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
        self.img_provider.update_image(qt)
        self.imageUpdated.emit("refresh")

if __name__ == "__main__":
    app = QApplication(sys.argv)
    provider = LiveImageProvider()
    engine = QQmlApplicationEngine()
    engine.addImageProvider("live", provider)
    backend = Backend(provider)
    engine.rootContext().setContextProperty("backend", backend)
    engine.load("interface.qml")
    sys.exit(app.exec_())